---
copyright:
  years: 2017
lastupdated: "2017-11-23"

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:codeblock: .codeblock}
{:screen: .screen}
{:tip: .tip}
{:pre: .pre}

# Generate, Access and Analyze Application Logs
This tutorial shows how the [IBM Cloud Log Analysis](https://console.bluemix.net/catalog/services/log-analysis) service can be used to understand and diagnose activities of an app deployed in the IBM Cloud. We are going to deploy a Python-based Cloud Foundry app, generate different types of logs, and search, analyze and visualize them using Elasticsearch and Kibana, two of the components offered by the IBM Cloud Log Analysis service.

## Objectives
* Provision the IBM Cloud Log Analysis service
* Deploy a Python-based Cloud Foundry app
* Generate different kind of log entries
* Access application logs
* Search and analyze logs
* Visualize logs

## Introduction
IBM Cloud offers three complementary services that help to obtain insights into application health, stability and usage:
* The [IBM Cloud Log Analysis](https://console.bluemix.net/catalog/services/log-analysis) service provides an easy-to-use interface to logs generated by applications running in the IBM Cloud. In the premium plans, even external log events can be fed into the service for consolidated storage and analysis.
* The [Availability Monitoring](https://console.bluemix.net/catalog/services/availability-monitoring) service can be used to perform regular tests on an application to check availability, including speed.
* Last, the [IBM Cloud Activity Tracker](https://console.bluemix.net/catalog/services/activity-tracker) has the capability to capture, store and visualize activities performed by IBM Cloud users and services in your account. Captured events can be stored and analyzed, e.g., to investigate security breaches or unauthorized access.

In this tutorial, we are going to take a look at how to generate, access and analyze application logs. The [documentation for IBM Cloud Log Analysis](https://console.bluemix.net/docs/services/CloudLogAnalysis/index.html) already includes a [tutorial on how to analyze logs for an app deployed in a Kubernetes cluster](https://console.bluemix.net/docs/services/CloudLogAnalysis/containers/tutorials/kibana_tutorial_1.html). Therefore, in this guide, we are going to use a Cloud Foundry app.

## Provision the Log Analysis Service
Applications running in the IBM Cloud generate diagnostic output, i.e. logs, that can be accessed without any additional service. By using the Log Analysis service it is possible to aggregate logs from various sources and retain them as long as needed. This allows to analyze the "big picture" when required and to troubleshoot more complex situations.

The Log Analysis service is found in the [IBM Cloud service catalog in the DevOps category](https://console.bluemix.net/catalog/?category=devops). Click on it and it the dialog select the region, organization and space to which you want to provision the service. This should be the same as for the app we are going to deploy in the next step. Once the correct values are set, click on `Create`.

By default the `Lite` plan is selected which allows for 500 MB of daily logs for the past 3 days. The `Premium` plans feature higher data volumes and longer log retention.

## Deploy a Cloud Foundry app
The ready-to-run [code for the database app is located in this Github repository](https://github.com/IBM-Bluemix/UPDATE_NAME). Clone or download the repository, then push the app to the IBM Cloud.

1. Clone the Github repository:
   ```bash
   git clone https://github.com/IBM-Bluemix/UPDATE_NAME
   cd UPDATE_NAME
   ```
2. Push the application to the IBM Cloud. You need to be logged in to the region, org and space in which the Log Analysis service was created. Copy and paste these commands one line at a time.
   ```bash
   bx login
   bx target --cf
   bx cf push your-app-name
   ```
3. Once the push process is finished you should be able to access the app.

## Generate Application Logs
Next, in order to work with application logs, is to create them. Did you know that the push process above already generated many log entries? Because apps deployed in the IBM Cloud are automatically linked with the Log Analysis service, nothing needs to be done from our side.

1. Now visit the web app. Its URI is listed under `urls` at the end of the diagnostic output generated by the push process. You can also find the application URI in the [IBM Cloud dashboard (console)](console.bluemix.net).

2. The application web UI allows to log a message at a chosen log level. The available log levels are `critical`, `error`, `warn`, `info` and `debug`. The application's logging infrastructure is configured to allow only log entries on or above a set level to pass. Initially, the level is set to `warn`. Thus, a message logged at `info` with a server setting of `warn` would not show up in the diagnostic output. The UI allows to change the server-side setting for the log level. Try it and generate log entries.

3. Take a look at the code in the file [`cloud-logging.py`](http://github.com/IBM-Bluemix/UPDATE_PATH/cloud-logging.py). The code contains `print` statements as well as calls to `logger` functions. Printed messages are written to the `stdout` stream (regular output, application console / terminal), logger messages appear in the `stderr` stream (error log).

4. Back in the application, generate several log entries by submitting messages at different levels. Change the server-side log level in-between to make it more interesting.

## Access Application logs
IBM Cloud offers multiple ways of accessing application logs, in our case for a Cloud Foundry app.

1. The first is using the command line. The following displays the recent logs. It is a great method to investigate errors when an app after the push is not starting:
```bash
bx cf logs your-app-name --recent
```
By leaving out the option `--recent` you would attach to the log stream and messages would be displayed the moment they get logged.

2. The second method is to use the [IBM Cloud console](https://console.bluemix.net). In the overview, navigate to your app, click on its entry to open the details and then go to `Logs`. Current logs are shown with the most recent at the bottom. On the upper right you can search for an entry or filter by log type. Selecting `Application (APP)`
![](images/solution12/Dashboard_LogsFilter.png)

3. The Log Analysis service offers access to the logs. In contrast to the first two, logs from all the apps in a space are available and not just the recent entries. When using the Lite plan, logs from the past 3 days are retained, for the Premium plans depending on your configuration.   
The logs can be accessed, searched and visualized using a browser-based UI (Kibana dashboard). You can directly launch it via a [region-specific URI](https://console.bluemix.net/docs/services/CloudLogAnalysis/kibana/analyzing_logs_Kibana.html#urls_kibana) or by navigating to the service in the [IBM Cloud dashboard](https://console.bluemix.net), clicking on the service details and then on `Launch`. [For details see this section in the Log Analysis documentation](https://console.bluemix.net/docs/services/CloudLogAnalysis/kibana/analyzing_logs_Kibana.html#launch_Kibana).   
We are going to discuss how to work with logs in Kibana in the next section.

## Search and Analyze Logs

When you open the Log Analysis / Kibana dashboard, by default it shows all available log entries of the past 15 minutes. Most recent entries are shown on the top, automatic refresh is turned off by default. The visible bar chart represents the count of messages per 30 seconds over those 15 minutes. We are going to modify what and how much is displayed and save this as `search query` for future use.

1. On the left side are the available fields that can be displayed and queried. Locate and click on `message`, then on the `add` button next to it. The dashboard should look similar to this now:   
![](images/solution12/Dashboard_MessagesAdded.png)

2. If you are seeing logs for more than one application, you can filter them based on the `app_name_str` field. Instead of `add` use the `+` next to an app name to only see entries for that application or the `-` to exclude the app's logs from the list.   
![](images/solution12/app_name_str.png)

3. Adjust the displayed interval by navigating to the upper right and clicking on `Last 15 minutes`. You can change the value to one of the predefined settings under `Quick`, to a sliding interval of your choice under `Relative` or to specific timestamps for start and end under `Absolute`. Adjust the value to `Last 24 hours`.

4. Next to the configuration of the interval is the auto-refresh setting. By default it is switched off, but you can change it.  Depending on the value the displayed bar chart and log entries are refreshed from every 5 seconds over minutes or hours to once a day.

5. Below the configuration is the search field. Here you can [enter and define search queries](https://console.bluemix.net/docs/services/CloudLogAnalysis/kibana/define_search.html#define_search). To filter for all logs reported as app errors and containing one of the defined log levels, enter the following:   
```
message:(CRITICAL|INFO|ERROR|WARN|DEBUG) && message_type_str:ERR
```   
It should look like shown below. The displayed log entries are now filtered based on the search criteria.   
![](images/solution12/SearchForMessagesERR.png)   

6. You can store the search criteria for future use by clicking `Save` in the configuration bar. Use `ERRlogs` as name.


## Visualize Logs
Now that we have a query defined, we can use it as foundation for a chart, a visualization of that data. We are going to create to visualizations and then use them to compose a dashboard.

### Pie Chart as Donut
1. Click on `Visualize` in the left navigation bar.
2. In the list of offered visualizations Locate `Pie chart` and click on it.
3. Now you can either enter a new filtering query or, on the right hand side, select the query `ERRlogs` that you saved earlier. Pick the saved query.
4. On the next screen, under `Select buckets type`, select `Split Slices`, then for `Aggregation` choose `Filters`. Add 5 filters having the values of `CRITICAL`, `ERROR`, `WARN`, `INFO` and `DEBUG` as shown here:   
![](images/solution12/VisualizationFilters.png)   
6. Click on `Options` (right to `Data`) and activate `Donut` as view option. Finally, click on the `play` icon to apply all changes to the chart. Now you should see a `Donut Pie Chart` similar to this one:   
![](images/solution12/Donut.png)   
7. Save the visualization as `DonutERR`.

### Metric
Now we are going to add another visualization, this time a `Metric`.
1. Create a metric
2. adjust filters
3. save it


### Dashboard
1. compose dashboard from the existing visualizations
2. if needed, add Markdown visualization for labels, etc.


## Expand the Tutorial
Do you want to learn more? Here are some ideas of what you can do next:
* Push the same app again with a different name or use the [app deployed in a Kubernetes cluster](https://console.bluemix.net/docs/services/CloudLogAnalysis/containers/tutorials/kibana_tutorial_1.html). Then, the Log Analysis dashboard (Kibana) will show the combined logs of all apps.
* Filter by a single app.
* Build a dashboard for all your apps.


## Related Content
* [Documentation for IBM Cloud Log Analysis](https://console.bluemix.net/docs/services/CloudLogAnalysis/index.html)
* [Logging facility for Python](https://docs.python.org/3/library/logging.html)
